{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`XGBoost` is well known to provide better solutions than other machine learning algorithms. In face, since its inception, it has become the 'state-of-the-art' machine learning algorithm to deal with structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Speed and performance**: Originally written in C++, it is comparatively faster than other ensemble classifiers.\n",
    "\n",
    "- **Core algorithm is parallelizable**: Because the core XGBoost algorithm is parallelizable, it can harness the power of multi-core computers. It is also parallelizable onto GPUs and across networks of computers making it feasible to train on very large datasets as well.\n",
    "\n",
    "- **Consistently outperforms other algorithm methods**: It has shown better performance on a variety of machine learning benchmark datasets.\n",
    "\n",
    "- **Wide variety of tuning parameters**: `XGBoost` internally has parameters for cross-validation, regularization, user-defined objective functions, missing values, tree parameters, scikit-learn compatible API, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting is a sequenctial technique which works on the principle of an ensemble. It combines a set of weak learners and delivers improved prediction accuary. At any instant `t`, the model outcomes are weighed based on the outcomes of previous instant `t-1`.\n",
    "\n",
    "The outcomes predicted correctly are given a lower weight and the ones misclassified are weighted higher. Note that a weak learner is one which is _slightly_ better than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, you should know about the default base learnes of `XGBoost`: **Tree Ensembles**. The _tree ensemble_ model is a set of classification and regression trees or `CART`. The trees are grown one after another, and attempts to reduce the misclassification rate are made in subsequent iterations.\n",
    "\n",
    "Each tree gives a different prediction score depending on the data it sees and the scores of each individual tree are summed up to get the final score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `XGBoost` in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "print(boston.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "print(boston.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "print(boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(boston.data)\n",
    "data.columns = boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  Price    506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT       Price  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target variable and rest of the variables using `.iloc` tp subset the data\n",
    "X, y = data.iloc[:, :-1], data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DMatrix.set_group of <xgboost.core.DMatrix object at 0x174bbfbb0>>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dmatrix.set_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost's Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, before building the model, you should be aware of the tuning parameters that XGBoost provides. THere are a plethora of tuning parameters for tree-based learnings in XGBoost, but the most common ones are:\n",
    "- `learning_rate`: step size shrinkage used to prevent overfitting, range(0,1).\n",
    "- `max_depth`: determines how deeply each tree is allowed to grow during any boosting round.\n",
    "- `subsample`: percentage of samples used per tree. Low value can lead to underfitting.\n",
    "- `colsample_bytree`: percentage of features used per tree. High value can lead to overfitting.\n",
    "- `n_estimators`: number of trees you want to build.\n",
    "- `objective`: determines the loss function to be used like `reg:linear` for regression problems, `reg:logistic` for classification problems with only decision, `binary:logistic` for classification problems with probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost also supports regularization parameters to penalize models as they become more complex and reduce them to simple (parsimonious) models.\n",
    "- `gamma`: controls whether a given node will split based on the expected reduction in loss after the split. A higher value leads to fewer splits. Supported only for tree-based learners.\n",
    "- `alpha`: L1 regularization on leaf weights. A large value leads to more regularization.\n",
    "- `lambda`: L2 regularization on leaf weights and is smoother than L1 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use XGBoost's relatively less popular linear base learners and one other tree learner known as dart. ALl you have to do is set the booster parameter to either `gbtree` (default), `gblinear`, or `dart`.\n",
    "\n",
    "Now, create the train and test set for cross-validation of the results using the `train_test_split` function with `test-size` at 20% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to instantiate on XGBoost regressor object by calling the `XGBRegressor()` class from the XGBoost library with the hyperparameters pass as arguments. For classification problems, you would have used the `XGBClassifier()` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                          max_depth = 5, alpha = 10, n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train, y_train)\n",
    "y_pred = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.517005\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `k-fold` Cross Validation using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build more robust models, it is common to do a `k-fold` cross validation where all the entries in the original training dataset are used for both training as well as validation. Also, each entry is used for validation just once.\n",
    "\n",
    "XGBoost supports `k-fold` cross validation via the `cv()` method, with `nfolds` parameter specified. It also supports many other parameters:\n",
    "- `num_boost_round`: denotes the number of trees you build\n",
    "- `metrics`: tells the evaluation metrics to be watched during CV\n",
    "- `as_pandas`: to return the results in a pandas DataFrame\n",
    "- `early_stopping_rounds`: finishes training of the model early if the hold-out metric (RMSE in our case) does not improve for a given number of rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a hyperparameter dictionary `params` which holds all the hyperparameters and their values as key-value pairs but will exclude the `n_estimators` from the hyperparameter dictionary because you will use `num_boost_rounds` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a 3-fold cross validation model by invoking XGBoost's cv() method adn store the results in a `cv_results` DataFrame\n",
    "# note that we are using `data_dmatrix` object created before\n",
    "\n",
    "params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50, early_stopping_rounds=10, metrics=\"rmse\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.680257</td>\n",
       "      <td>0.025607</td>\n",
       "      <td>21.719121</td>\n",
       "      <td>0.019025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.740499</td>\n",
       "      <td>0.072068</td>\n",
       "      <td>19.818879</td>\n",
       "      <td>0.061769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.007202</td>\n",
       "      <td>0.119744</td>\n",
       "      <td>18.109862</td>\n",
       "      <td>0.129375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.463924</td>\n",
       "      <td>0.115086</td>\n",
       "      <td>16.587235</td>\n",
       "      <td>0.182340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.990313</td>\n",
       "      <td>0.112001</td>\n",
       "      <td>15.132976</td>\n",
       "      <td>0.166282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0        21.680257        0.025607       21.719121       0.019025\n",
       "1        19.740499        0.072068       19.818879       0.061769\n",
       "2        18.007202        0.119744       18.109862       0.129375\n",
       "3        16.463924        0.115086       16.587235       0.182340\n",
       "4        14.990313        0.112001       15.132976       0.166282"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49    3.862102\n",
      "Name: test-rmse-mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print((cv_results[\"test-rmse-mean\"]).tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reach an even lower RMSE for a different set of hyper-parameters. You may consider applying techniques like Grid Search, Random Search, and Bayesian Optimization to reach the optimal set of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Boosting Trees and Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also visualize individual trees from the fully boosted model that XGBoost creates using the entire housing dataset. XGBoost has a `plot_tree()` function that makes this type of visualization easy. Once you train a model using the XGBoost learning API, you can pass it to the `plot_tree()` function along with the number of trees you want to plot using the `num_trees` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "You must install graphviz to plot tree",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py:171\u001b[0m, in \u001b[0;36mto_graphviz\u001b[0;34m(booster, fmap, num_trees, rankdir, yes_color, no_color, condition_node_params, leaf_node_params, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=169'>170</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=170'>171</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgraphviz\u001b[39;00m \u001b[39mimport\u001b[39;00m Source\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=171'>172</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/lsantos/Documents/lighthouse-data-notes/week_5/day_3/other_ensemble_techniques.ipynb Cell 41'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lsantos/Documents/lighthouse-data-notes/week_5/day_3/other_ensemble_techniques.ipynb#ch0000039?line=0'>1</a>\u001b[0m xgb\u001b[39m.\u001b[39;49mplot_tree(xg_reg,num_trees\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lsantos/Documents/lighthouse-data-notes/week_5/day_3/other_ensemble_techniques.ipynb#ch0000039?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mfigure.figsize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [\u001b[39m50\u001b[39m, \u001b[39m10\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lsantos/Documents/lighthouse-data-notes/week_5/day_3/other_ensemble_techniques.ipynb#ch0000039?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py:247\u001b[0m, in \u001b[0;36mplot_tree\u001b[0;34m(booster, fmap, num_trees, rankdir, ax, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=243'>244</a>\u001b[0m \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=244'>245</a>\u001b[0m     _, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=246'>247</a>\u001b[0m g \u001b[39m=\u001b[39m to_graphviz(booster, fmap\u001b[39m=\u001b[39;49mfmap, num_trees\u001b[39m=\u001b[39;49mnum_trees, rankdir\u001b[39m=\u001b[39;49mrankdir,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=247'>248</a>\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=249'>250</a>\u001b[0m s \u001b[39m=\u001b[39m BytesIO()\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=250'>251</a>\u001b[0m s\u001b[39m.\u001b[39mwrite(g\u001b[39m.\u001b[39mpipe(\u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py:173\u001b[0m, in \u001b[0;36mto_graphviz\u001b[0;34m(booster, fmap, num_trees, rankdir, yes_color, no_color, condition_node_params, leaf_node_params, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=170'>171</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgraphviz\u001b[39;00m \u001b[39mimport\u001b[39;00m Source\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=171'>172</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=172'>173</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mYou must install graphviz to plot tree\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=173'>174</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(booster, XGBModel):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/xgboost/plotting.py?line=174'>175</a>\u001b[0m     booster \u001b[39m=\u001b[39m booster\u001b[39m.\u001b[39mget_booster()\n",
      "\u001b[0;31mImportError\u001b[0m: You must install graphviz to plot tree"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQiElEQVR4nO3dQWjT9//H8VcacxDmppiJMw2rjKp1Uyc2LYKizENtL2V4cf3hmJPaS8XLoLjDPOzibg46ZxdXZQfpRcHCdGUbjg2x8h2YWu06kq6whjC1FmXQw9r6+R/k1/7yr/abNmkyfT8f8Dmk+fjtux/cc1nSZAFJTgCAF15ZqQcAABQHwQcAIwg+ABhB8AHACIIPAEYQfAAwwjf4X3/9te7evav+/v5n7vn888+VTCbV19enrVu3FnRAAEBh+Ab/3Llz2rt37zPvr6+vV2VlpSorK3X48GF9+eWXBR0QAFAYvsH/5ZdfNDY29sz7Gxsb9c0330iSbty4oeXLl2v16tWFmxAAUBBL8r1AJBLRyMjI9O10Oq1IJKK//vpr1t7m5mYdPnxYkrR+/Xr9/vvv+X57ADDl9ddf16pVqxb0Z/MOfiAQmPU1557+aQ3xeFzxeFyS5HmeYrFYvt8eAEzxPG/Bfzbv39JJp9OKRqPTt8vLy5XJZPK9LACgwPIOfnd3t95//31JUm1trR49evTUp3MAAKXl+5TO+fPntXv3boXDYY2MjOj48eMKhUKSpI6ODl2+fFkNDQ1KpVIaHx/XwYMHF31oAMD8+Qa/qanJ9yKtra0FGQYAsHh4py0AGEHwAcAIgg8ARhB8ADCC4AOAEQQfAIwg+ABgBMEHACMIPgAYQfABwAiCDwBGEHwAMILgA4ARBB8AjCD4AGAEwQcAIwg+ABhB8AHACIIPAEYQfAAwguADgBEEHwCMIPgAYATBBwAjCD4AGEHwAcAIgg8ARhB8ADCC4AOAEQQfAIwg+ABgBMEHACMIPgAYQfABwAiCDwBG5BT8uro6DQ4OKplMqq2tbdb9L7/8srq7u5VIJHT79m198MEHhZ4TAFAAbq5VVlbmUqmUW7t2rQuFQi6RSLiqqqqsPceOHXMnTpxwklw4HHYPHjxwoVBozut6njfn/SwWi8WavfJpp+8j/JqaGqVSKQ0PD2tiYkJdXV1qbGzM2uOc07JlyyRJL730ksbGxjQ5Oel3aQBAEfkGPxKJaGRkZPp2Op1WJBLJ2tPe3q6qqiplMhn19/fr6NGjcs7NulZzc7M8z5PneQqHwwUYHwCQK9/gBwKBWV/7/zGvq6tTIpHQmjVr9Pbbb6u9vX36Ef//isfjisViisViGh0dzWNsAMB8+QY/nU4rGo1O3y4vL1cmk8nac/DgQV28eFGSNDQ0pOHhYW3YsKHAowIA8uEbfM/zVFlZqYqKCoVCIe3fv1/d3d1Ze/7880/t2bNHkrRq1SqtX79ef/zxx+JMDABYkCV+G6amptTa2qqenh4Fg0F1dnZqYGBALS0tkqSOjg59+umnOnfunG7duqVAIKC2tjY9ePBg0YcHAOQuoCe/rlN0nucpFouV4lsDwHMrn3byTlsAMILgA4ARBB8AjCD4AGAEwQcAIwg+ABhB8AHACIIPAEYQfAAwguADgBEEHwCMIPgAYATBBwAjCD4AGEHwAcAIgg8ARhB8ADCC4AOAEQQfAIwg+ABgBMEHACMIPgAYQfABwAiCDwBGEHwAMILgA4ARBB8AjCD4AGAEwQcAIwg+ABhB8AHACIIPAEYQfAAwguADgBE5Bb+urk6Dg4NKJpNqa2t76p5du3bp5s2bun37tn766adCzggAKBA31yorK3OpVMqtXbvWhUIhl0gkXFVVVdaeV155xd25c8dFo1Enyb366qtzXlOS8zzPdw+LxWKxslc+7fR9hF9TU6NUKqXh4WFNTEyoq6tLjY2NWXuampp08eJFjYyMSJLu37/vd1kAQJH5Bj8SiUyHXJLS6bQikUjWnnXr1mnFihW6evWqfv31Vx04cOCp12pubpbnefI8T+FwOM/RAQDzscRvQyAQmPU151z2RZYs0bZt27Rnzx4tXbpU169fV29vr5LJZNa+eDyueDwuSfI8L5+5AQDz5Bv8dDqtaDQ6fbu8vFyZTGbWntHRUY2Pj2t8fFw///yztmzZMiv4AIDS8X1Kx/M8VVZWqqKiQqFQSPv371d3d3fWnkuXLmnnzp0KBoNaunSpamtr9dtvvy3a0ACA+fN9hD81NaXW1lb19PQoGAyqs7NTAwMDamlpkSR1dHRocHBQ3333nW7duqXHjx/rzJkzunPnzqIPDwDIXUBPfl2n6DzPUywWK8W3BoDnVj7t5J22AGAEwQcAIwg+ABhB8AHACIIPAEYQfAAwguADgBEEHwCMIPgAYATBBwAjCD4AGEHwAcAIgg8ARhB8ADCC4AOAEQQfAIwg+ABgBMEHACMIPgAYQfABwAiCDwBGEHwAMILgA4ARBB8AjCD4AGAEwQcAIwg+ABhB8AHACIIPAEYQfAAwguADgBEEHwCMIPgAYATBBwAjCD4AGJFT8Ovq6jQ4OKhkMqm2trZn7quurtbk5KT27dtXsAEBAIXhG/yysjJ98cUXqq+v18aNG/Xee++pqqrqqfs+++wz9fT0LMqgAID8+Aa/pqZGqVRKw8PDmpiYUFdXlxobG2ftO3LkiC5cuKB79+4tyqAAgPz4Bj8SiWhkZGT6djqdViQSydqzZs0avfvuuzp9+vSc12pubpbnefI8T+FweIEjAwAWwjf4gUBg1tecc1m3T548qba2Nj1+/HjOa8XjccViMcViMY2Ojs5zVABAPpb4bUin04pGo9O3y8vLlclksvZUV1erq6tLkhQOh9XQ0KDJyUldunSpwOMCAPLh5lrBYNANDQ25iooKFwqFXCKRcBs3bnzm/rNnz7p9+/bNeU1JzvM83z0sFovFyl75tNP3Ef7U1JRaW1vV09OjYDCozs5ODQwMqKWlRZLU0dHhdwkAwL9AQE/KX3Se5ykWi5XiWwPAcyufdvJOWwAwguADgBEEHwCMIPgAYATBBwAjCD4AGEHwAcAIgg8ARhB8ADCC4AOAEQQfAIwg+ABgBMEHACMIPgAYQfABwAiCDwBGEHwAMILgA4ARBB8AjCD4AGAEwQcAIwg+ABhB8AHACIIPAEYQfAAwguADgBEEHwCMIPgAYATBBwAjCD4AGEHwAcAIgg8ARhB8ADCC4AOAETkFv66uToODg0omk2pra5t1f1NTk/r6+tTX16dr165p8+bNBR8UAJA/N9cqKytzqVTKrV271oVCIZdIJFxVVVXWnu3bt7vly5c7SW7v3r2ut7d3zmtKcp7n+e5hsVgsVvbKp52+j/BramqUSqU0PDysiYkJdXV1qbGxMWvP9evX9fDhQ0lSb2+vysvL/S4LACgy3+BHIhGNjIxM306n04pEIs/cf+jQIV25cuWp9zU3N8vzPHmep3A4vIBxAQALtcRvQyAQmPU159xT9+7evVuHDh3Sjh07nnp/PB5XPB6XJHmeN585AQB58g1+Op1WNBqdvl1eXq5MJjNr36ZNm3TmzBnV19drbGyssFMCAApizif5g8GgGxoachUVFdMv2m7cuDFrTzQadclk0m3fvr0oLzywWCyW1ZVPO30f4U9NTam1tVU9PT0KBoPq7OzUwMCAWlpaJEkdHR365JNPtHLlSp06dUqSNDk5qVgs5ndpAEARBfSk/EXneR7/UgCAecqnnbzTFgCMIPgAYATBBwAjCD4AGEHwAcAIgg8ARhB8ADCC4AOAEQQfAIwg+ABgBMEHACMIPgAYQfABwAiCDwBGEHwAMILgA4ARBB8AjCD4AGAEwQcAIwg+ABhB8AHACIIPAEYQfAAwguADgBEEHwCMIPgAYATBBwAjCD4AGEHwAcAIgg8ARhB8ADCC4AOAEQQfAIwg+ABgBMEHACNyCn5dXZ0GBweVTCbV1tb21D2ff/65ksmk+vr6tHXr1oIOCQAoDDfXKisrc6lUyq1du9aFQiGXSCRcVVVV1p76+np3+fJlJ8nV1ta63t7eOa8pyXme57uHxWKxWNkrn3b6PsKvqalRKpXS8PCwJiYm1NXVpcbGxqw9jY2N+uabbyRJN27c0PLly7V69Wq/SwMAimiJ34ZIJKKRkZHp2+l0WrW1tb57IpGI/vrrr6x9zc3NOnz4sCTprbfekud5eQ3/ogiHwxodHS31GP8KnMUMzmIGZzFj/fr1C/6zvsEPBAKzvuacm/ceSYrH44rH45Ikz/MUi8VyHvRFxlnM4CxmcBYzOIsZ+TxQ9n1KJ51OKxqNTt8uLy9XJpOZ9x4AQGn5Bt/zPFVWVqqiokKhUEj79+9Xd3d31p7u7m69//77kqTa2lo9evRo1tM5AIDS8n1KZ2pqSq2trerp6VEwGFRnZ6cGBgbU0tIiSero6NDly5fV0NCgVCql8fFxHTx40Pcbf/XVV/lP/4LgLGZwFjM4ixmcxYx8ziKgJ7+uAwB4wfFOWwAwguADgBGLHnw+lmGG31k0NTWpr69PfX19unbtmjZv3lyCKYsjl78XklRdXa3JyUnt27eviNMVVy5nsWvXLt28eVO3b9/WTz/9VNwBi8jvLF5++WV1d3crkUjo9u3b+uCDD4o/ZBF8/fXXunv3rvr7+5+5Z6HdXLS3AC/WxzI8jyuXs9i+fbtbvny5k+T27t1r+iz+u+/HH3903377rdu3b1/J5y7VWbzyyivuzp07LhqNOknu1VdfLfncpTqLY8eOuRMnTjhJLhwOuwcPHrhQKFTy2Qu9du7c6bZu3er6+/ufev9Cu7moj/D5WIYZuZzF9evX9fDhQ0lSb2+vysvLSzDp4svlLCTpyJEjunDhgu7du1eCKYsjl7NoamrSxYsXp9/Nfv/+/VKMuuhyOQvnnJYtWyZJeumllzQ2NqbJyclSjLuofvnlF42NjT3z/oV2c1GD/6yPXJjvnhfBfH/OQ4cO6cqVK8UYrehyOYs1a9bo3Xff1enTp4s9XlHlchbr1q3TihUrdPXqVf366686cOBAsccsilzOor29XVVVVcpkMurv79fRo0ef+q7+F91Cu+n7e/j5KOTHMjzv5vNz7t69W4cOHdKOHTsWe6ySyOUsTp48qba2Nj1+/LhYY5VELmexZMkSbdu2TXv27NHSpUt1/fp19fb2KplMFmvMosjlLOrq6pRIJPTOO+/ojTfe0Pfff68tW7bo77//LtaY/woL7eaiBp+PZZiR68+5adMmnTlzRvX19XP+J93zLJezqK6uVldXl6QnH5zV0NCgyclJXbp0qaizLrZc/xkZHR3V+Pi4xsfH9fPPP2vLli0vXPBzOYuDBw/qxIkTkqShoSENDw9rw4YN5j6IMZ9uLtoLD8Fg0A0NDbmKiorpF2E2btyYtaehoSHrxYcbN26U/AWTUp1FNBp1yWTSbd++veTzlvos/nedPXv2hX3RNpez2LBhg/vhhx9cMBh0S5cudf39/e7NN98s+eylOItTp06548ePO0lu1apVLp1Ou5UrV5Z89sVYr7/++jNftM2jm4s7dH19vfv9999dKpVyH3/8sZPkWlpaXEtLy/Se9vZ2l0ql3K1bt9y2bdtKftClOot4PO7GxsbczZs33c2bN1/o/0lMLn8v/rte5ODnehYfffSRu3Pnjuvv73dHjx4t+cylOovXXnvN9fT0uFu3brn+/n73n//8p+QzL8Y6f/68y2Qy7p9//nEjIyPuww8/LEg3+WgFADCCd9oCgBEEHwCMIPgAYATBBwAjCD4AGEHwAcAIgg8ARvwfxxX+r2AHWPwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_tree(xg_reg,num_trees=0)\n",
    "plt.rcParams['figure.figsize'] = [50, 10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAEWCAYAAADRrhi8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA170lEQVR4nO3deVQVV9Y28IfLKCqgQWUwguKE4oAah3aewQk7GgU6LUajphWNcWiNKx013R2HNnGKrxpBBBNeYjREjEZRg4odB4IXchFUUIwggiKITCrg+f7go16uDGICt6jL81vrrEVVnaramxg2VbeobQBAgIiISEFUcgdARET0qli8iIhIcVi8iIhIcVi8iIhIcVi8iIhIcVi8iIhIcVi8iOqRDz/8EHv27JE7DCJFEBwc+jCSk5NFQUGByM3NlYatre0fPubIkSNlz02OsXr1arF//37Z4+DgqGzwyov0ysSJE9G0aVNp3Lt3T9Z4DA0NZT3/76XUuKlhkb2CcnDUxqjqKsnCwkL4+fmJtLQ0kZqaKv75z38KlUolAIh27dqJ06dPi8zMTPHgwQPx1VdfCUtLSwFABAUFiZKSEulqbvny5WLo0KEiJSWlyvOuXr1afPvtt2L//v0iJydHzJ49u9rzvzjKX+04ODgIIYSYOXOmuHPnjsjKyhLz5s0Tffr0EbGxsSI7O1ts375d2tfHx0ecP39ebNu2TTx69EgkJCSIESNGSNttbW3F4cOHxcOHD0ViYqJ49913tc5bPu4FCxaIp0+fimfPnonc3FwRExMjAIiZM2eK+Ph48fjxY3Hz5k0xd+5c6Rhl35slS5aIjIwMkZaWJmbOnCltNzMzE5s2bRK3b98Wjx49EpGRkcLMzEwAEP369RP//e9/RXZ2toiJiRFDhw6V/d8TR70fsgfAwVEro6riFRoaKnbt2iXMzc1FixYtxKVLl6Qfuk5OTmLUqFHCxMREWFtbi7Nnz4rNmzdXecyaFK9nz54JDw8PYWBgIMzMzKo9/4ujsuK1c+dOYWpqKkaPHi0KCwtFaGioaNGihbCzsxMZGRliyJAhAigtXkVFRWLx4sXCyMhITJs2TTx69Eg0a9ZMABBnzpwRO3bsEKampqJHjx7i/v37UnGrLO7KbhuOGzdOtGvXTgAQQ4YMEfn5+cLV1VX63hQVFYm1a9cKIyMj4e7uLvLz84WVlZUAIL744gsREREh7OzshEqlEgMGDBAmJibCzs5OZGZmCnd3d2FgYCBGjRolMjMzhbW1tez/pjjq9ZA9AA6OWhnJyckiNzdXZGdni+zsbBEaGipatmwpnjx5Iv2GD0B4enqKn376qdJjeHh4iCtXrmgd81WL19mzZ6Vtr3r+yoqXnZ2dtD0zM1NMmzZNWj548KB4//33BVBavO7evat1vEuXLom3335btG7dWhQXF4smTZpI2z799FMREBBQadwvxlLVCA0NFYsWLZK+NwUFBcLQ0FDanpGRIfr16ycMDAxEQUGB6N69e4Vj/P3vfxdBQUFa644fPy5mzJgh+78pjvo7jECkRyZPnozTp09Ly2+88QaMjY21PvtSqVRISUkBALRo0QLbtm3D4MGD0bRpU6hUKmRnZ/+hGMqODQAODg7Vnr8mMjIypK8LCwsrLDdp0kRavnv3rta+v/32G+zs7GBnZ4esrCzk5eVpbevTp0+lcVfFzc0Nq1evRseOHaFSqWBubg6NRiNtf/jwIUpKSqTlgoICNGnSBNbW1mjUqBFu3rxZ4ZgODg546623MHHiRGmdsbExIiIiXhoPNVwsXqTXUlJS8PTpU1hbW2v9UC2zbt06CCHQvXt3ZGVlwcPDA1988YW0XQihNT8/Px/m5ubSskqlQosWLbTmlN/nZeevbfb29lrLbdq0QVhYGNLS0tC8eXM0adJEKmBt2rTRKnYv5vrisomJCQ4dOoQZM2bg8OHDKC4uRmhoKAwMDF4aV2ZmJgoLC+Hk5IRff/1Va1tKSgr279+PuXPnvlKu1LDxaUPSa+np6QgPD8dnn32Gpk2bwsDAAO3atcOQIUMAAE2bNkVeXh4ePXoEOzs7LF++XGv/jIwMtGvXTlq+ceMGzMzMMG7cOBgZGeGjjz6Cqanp7z5/bWvZsiUWLVoEIyMjTJ06Fc7Ozjh27BhSU1Px888/Y926dTA1NUW3bt0we/ZsfP3111UeKyMjA46OjlJxMjExgampKR48eIDi4mK4ublhzJgxNYpLCIG9e/fi888/h62tLVQqFfr37w8TExN89dVXmDhxIsaMGQOVSgVTU1MMHTq0QiEmKo/Fi/TejBkzYGJigvj4eGRnZ+PgwYOwtbUFAKxduxa9evVCTk4Ojh49iu+++05r33Xr1uGjjz5CdnY2li5disePH2P+/Pnw8/PD3bt3kZ+fj9TU1N99/tp26dIldOjQAZmZmfj3v/+NqVOnIisrCwDg5eUFR0dHpKWlITQ0FKtXr8apU6eqPNa3334LoPRWYHR0NPLy8rBo0SIcOHAA2dnZ8Pb2RlhYWI1jW7ZsGTQaDaKiopCVlYUNGzZApVIhNTUVHh4eWLVqFR48eICUlBQsX74cKhV/PFHVDFD64RcRKZyPjw/effddDB48WO5QiOocf7UhIiLFYfEiIiLF4W1DIiJSHF55ERGR4vDvvCrx9OnTCn+Lok86dOiAxMREucOoE8xNufQ5v4aSm4ODA1q2bKmzc8v+mo/6NvLy8mSPoS5HVFSU7DEwN+bWkPJrKLnpMk/eNiQiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8SIioj/M398fPXr0gEajkdZNnToVcXFxKCkpQe/evavcd+zYsbh27RoSExOxYsWKGp1P0cWruLgYarUacXFxiImJwQcffAADAwMAwNChQ3HkyBEAQMuWLXHkyBHExMTg6tWrOHr0qJxhExHpnX379lVo+xIXF4c333wT586dq3I/lUqFHTt2wN3dHV26dIGXlxecnZ1fej5F9/MqLCyEq6srAKBFixYIDg6GpaUl1qxZozXvk08+wcmTJ7Ft2zYAQLdu3XQdKhGRXouMjERxcTFUqv+7Jrp27dpL9+vbty+SkpKQnJwMAAgJCYGHhwcSEhKq3U/Rxau8Bw8eYO7cuYiKiqpQvGxtbREeHi4tl7+srYxJIzN8prlQF2HWC62dOuttfsxNufQ5P13ntrTbAJ2d64+yt7dHSkqKtJyamop+/fq9dD+9KV4AkJycDJVKVaGT544dO/DNN9/A19cXp06dQkBAAO7du6c1Z86cOZg7dy4AwNBABW8nF53FrWuvmTbS2/yYm3Lpc366zm1IVJTOzuXs7IyoP3C+so96yhNCvHQ/vSpeQOXfiPDwcLRr1w5ubm5wd3eHWq2Gi4sLMjMzpTl79uzBnj17AADPSooRfDNOZzHrmreTi97mx9yUS5/z03VuS9/Q3ZVXVFQU3njjDQBAbGzsK++fmpqK119/XVpu3bo10tLSarSv7G2kf+/Izc3VWm7btq3IzMwUAMTQoUPFkSNHKt3vyJEj4s0336zyuHl5ebLnVpejobQk17ehz7npe34NJbfY2Fih0WgqzImIiBC9e/eudH9DQ0Nx8+ZN4ejoKIyNjUVMTIzo0qXLS8+r6KcNy7O2tsauXbvwxRdfVNg2fPhwNGrUCADQpEkTODk54c6dO7oOkYhIbwUHB6Nz587o1KkTUlJSMGvWLEyePBkpKSkYMGAAjh49iuPHjwMofQ6h7KnvkpIS+Pr64sSJE0hISMCBAwcQHx//0vMp+rZho0aNoFarYWxsjOLiYuzfvx+ff/55hXm9e/fGF198IT0J4+fnh19++UWGiImI9JO3t7fWLcQy33//fYW59+7dw/jx46XlH3/8ET/++OMrnU/RxcvIqOrwz549i7NnzwIANm3ahE2bNukqLCIiqmN6c9uQiIgaDhYvIiJSHBYvIiJSHBYvIiJSHBYvIiJSHBYvIiJSHBYvIiJSHBYvIiJSHBYvIiI95O/vj4yMDK0WUM2aNUN4eDhu3LiB8PBwWFlZVbrv7+lsrGuKL15l3ZQ1Gg3CwsJgaWkJAHBwcIAQAp988ok097XXXsOzZ8+wfft2ucIlItKJffv2wc3NTWvdypUrcfr0aXTs2BGnT5/GypUrK+z3ezsb65rii1dZN+Vu3bohKysLCxYskLbdvHkTEyZMkJbfeustXL16VY4wiYh0KjIyEllZWVrrPDw8EBgYCAAIDAzE5MmTK+xXvrNxUVGR1Nm4vlH0uw1fdOHCBXTv3l1aLiwsREJCAnr37o3o6GhMnz4dBw4cgJ2dXbXHYSdl5WJuyqXX+T2RO4BSrVq1Qnp6OgAgPT29QuNe4Pd3NtY1xV95lVGpVBg5ciTCwsK01oeEhMDT0xP29vYoKSmpcZMzIqKG6Pd2NtY1xV95lbVFcXR0RHR0NE6ePKm1/fjx4/jnP/+JjIwMfPPNN1UeZ86cOZg7dy4AwNBApbftyAG2W1cqfc4N0O/8mj43QFRUlM7Pa2JiAicnJ+ncZmZmiImJQVFREYyNjdGoUaMKcTVu3Bh2dnbo2bMnAMDGxgYAMGBA5d2ZnZ2dZckNqAedOP/IKOumbGFhIc6dOycWLlwoAAgHBwepo6e/v7+4d++eaN68ufDx8RHbt2+v9pjspKzcwdyUO/Q5P7lyK/9zEIDYuHGjWLFihQAgVqxYITZs2FBhn1ftbFw+N13mqTe3DR8/foxFixZh2bJlFfp8ffbZZ1ixYkWFDy+JiPRVcHAwLly4oNXZeP369Rg9ejRu3LiB0aNHY/369QBqp7Oxrin+tmF5MTExiI2NhaenJyIjI6X18fHx9fKbT0RUV7y9vStdP2rUqArraqOzsa4pvng1bdpUa3nSpEnS1926daswPzAwUHpUlIiIlElvbhsSEVHDweJFRESKw+JFRESKw+JFRESKw+JFRESKw+JFRESKw+JFRESKw+JFRESKw+JFRESKw+JFRKSH/P39kZGRAY1GI61r1qwZwsPDcePGDYSHh8PKyqrSfceOHYtr164hMTERK1as0FHEr0b24pWbmwsAcHBwgBACvr6+0rbt27fDx8cHABAQEIBbt24hJiYG169fR2BgoFZTybLjlPHx8cH27dsBAB07dkRERATUajXi4+Oxe/fuuk6LiEhW+/btg5ubm9a6lStX4vTp0+jYsSNOnz6NlStXVthPpVJhx44dcHd3R5cuXeDl5QVnZ2ddhV1j9erdhhkZGXj//fexe/duFBUVVdi+fPlyHDp0CACwePFiREREwMXFpdK55W3btg2bN2+WGlW6uFTfM4idlJWLuSmXXucnQyflyMhIODg4aK3z8PDAsGHDAJS+5/XMmTMVCljfvn2RlJSE5ORkAKUNfT08PJCQkKCTuGtK9iuv8h48eIDTp09LV1vV2bJlC9LT0+Hu7v7Suba2tkhNTZWW4+Li/lCcRERK1KpVK6SnpwMA0tPT0bJlywpz7O3tkZKSIi2npqbC3t5eZzHWVL268gKA9evX48cff8TevXtfOvfKlSvo3LmzdEVVlc2bN+Onn37Czz//jPDwcAQEBCAnJ0drDjsp6wfmplz6nF996aTcpEkTrTiaNm1aIa5mzZrBwsJC6qTcvHlzNG7cGP3796/0HHJ1Uq53xev27du4fPlylb1oyjMwMKh2uxACQOm93xMnTsDNzQ0eHh6YN28eevTogWfPnklz9+zZgz179gAAnpUUI/im/l6deTu56G1+zE259Dm/IU+M8MYbb+j8vA4ODvjhhx+kc1+7dg0TJ05Eeno6bGxscObMmQpx9e/fH2vWrJE+Lyu7rVjWuPJFUVFR0jF0WcTqXfECgE8//RQHDx7EuXPnqp3n6uqK06dPAwAKCwthbGwsff7VvHlzZGZmSnPv3buHgIAABAQEQKPRwMXFBVeuXKn0uM8Kn2BptwG1lE39MyQqCkvf0M/8mJty6XN+clyZVCYsLAw+Pj7YsGEDfHx8cPjw4QpzoqKi0KFDBzg6OuLu3bvw9PSs0cWErtWrz7zKXL9+HfHx8ZgwYUKVcxYuXAhbW1scP34cAHD27Fm8/fbbAAAzMzNMmzYNERERAEof+zQyKq3TrVq1wmuvvYa7d+/WcRZERPIJDg7GhQsX0KlTJ6SkpGDWrFlYv349Ro8ejRs3bmD06NHS1ZStrS2OHj0KACgpKYGvry9OnDiBhIQEHDhwoN52ohdyjtzcXAFAODg4CI1GI63v3r27KCkpET4+PgKACAgIELdu3RIxMTHixo0bIigoSNjb20vz7ezsxJEjR4RarRYxMTFiyZIl0rbPPvtMXLt2TcTExIiYmBjxl7/8pdqY8vLyZP2e1PWIioqSPQbmxtwaUn4NJTcd5yl/8vVtsHgpdzA35Q59zq+h5KbLPOvlbUMiIqLqsHgREZHisHgREZHisHgREZHisHgREZHisHgREZHisHgREZHisHgREZHisHgRUYO1ePFixMXFQaPRIDg4GKamphXmbN26FYmJiYiNjYWrq6sMUVJl6k3xerETMlB5B+QxY8ZArVZDrVYjNzcX165dg1qtRmBgIABg8uTJEEKgU6dOAICLFy9CrVbjt99+w/3796V9X2zSRkQNi52dHRYtWoQ+ffqgW7duMDQ0hKenp9Ycd3d3dOjQAR06dMDcuXOxc+dOmaKlF9XLt8qXqawDclxcHMLDwwEAERERWLZsGaKjo6V9vLy8EBkZCU9PT6xdu1bqQePj44M+ffpg4cKFLz0vOykrF3NTMBm6DRsZGaFRo0YoKiqCubk50tLStLZ7eHggKCgIAHDp0iVYWVnBxsZGauhI8qk3V16VedUOyI0bN8bAgQMxe/bsCr9BERGVl5aWhk2bNuHOnTu4d+8ecnJycPLkSa05Sukq3BDV6yuvmnRALm/y5Mk4fvw4EhMTkZWVBVdXV6jV6hqdi52U9QNzUy5ddxs2NDSEk5MTkpKSUFJSgnHjxuHmzZvIysqS5rRv3x5+fn7Iy8sDUPpRRlBQEAoKCl7pXHJ1G9YFdlKuRE06IJfn5eWFLVu2AABCQkLg5eVV4+LFTsr6gbkpl667DU+dOhVubm549913AQB//etf0b9/fyxYsECas2vXLpw5cwYhISEASjsRjxw58pVvG5bvNqxv5OqkDNSDV+oD/9fXq7qh0WhEr169pOWIiAjRu3dvAUA0b95cFBQUiNu3b4vk5GRx584d8dtvv0lzfXx8xPbt22sUC1uiKHcwN+UOXefXt29fERcXJxo1aiQAiH379glfX1+tOePGjRPHjh0TAES/fv3EpUuXFJGbXP/d2BLl/3uVDshTp05FUFAQHB0d0bZtW7Rp0wbJyckYNGiQLkMmIoW4fPkyDh48iCtXrkCj0UClUuHLL7/EvHnzMG/ePADAsWPHcOvWLSQlJWHPnj2YP3++zFFTmXpz29Dc3Fzrg9HPP/8crVu3xtatW/HkSeljSMuXL0dGRkal+3t5eUktrcscOnQI3t7eOH/+fN0FTkSKtWbNGqxZs0Zr3e7du7WWfX19dRgRvQrZLzvr2+BtQ+UO5qbcoc/5NZTceNuQiIioGixeRESkOCxeRESkOCxeRESkOCxeRESkOCxeRESkOCxeRESkOCxeRESkOCxeRNRgsZOycjWI4lVcXAy1Wo2YmBhER0djwIABcodERDJjJ2VlqzfvNqxLhYWF0m9MY8aMwbp16zBs2LAq57OTsnIxNwVjJ2V6BTW68mrXrh1MTEwAAEOHDsXChQthaWlZp4HVFQsLC2RnZ8sdBhHJjJ2Ulc0ApS85rJZarUafPn3g6OiIEydOICwsDJ06dcL48eN1EOIfV1xcDI1GAzMzM9ja2mLEiBG4cuWK1pzynZR79e6N+0/y5QhVJ14zbYSHTwvlDqNOMDflavrcAAkJCTo7X1kn5Vu3bqGkpATt2rVDdnZ2hU7K6enpWp2UU1NTf1cnZV3mpksv5qarpps1Kl7R0dHo3bs3li1bhidPnuCLL77AlStX0KtXLx2E+Mfl5uaiadOmAID+/fvDz88PLi5Vt1N/VlKM7fH62bIb0O+OvMxNuZTSSXnYsGHspFzOi52UdZnnS189f/HiReHp6Sk0Go1wdHQUQGlX45rsWx/Gi12a09PTRYsWLaqcz5Yoyh3MTbmDnZSVOeRqiVKjBzbeeecdvPfee/j3v/+N27dvw9HREV999VVNdq13OnXqBENDQzx8+FDuUIhIRuU7KZc9kVzWSRkobUp57NgxjBs3DklJSSgoKMA777wjc9RUXo2qnJmZmejYsaPsVf73jOLiYqFWq4VarRYxMTFi3Lhx1c7nlZdyB3NT7tDn/BpKbvXuymvChAnYtGkTTExM0K5dO/To0QOffPIJPDw8arK77IyMGsRfBBARNRg1elR+zZo16Nu3Lx49egQAiI2NRdu2besyLiIioirVqHgVFxfj8ePHWuuEEHUSEBER0cvUqHjFxcXBy8sLhoaGaN++PbZt24aff/65rmMjIiKqVI2K18KFC9G1a1c8ffoUwcHByMnJweLFi+s4NCIiosq99EkGlUqFsLAwjB49Gh999JEuYiIiIqrWS6+8nj9/joKCAlhYWOgiHiIiopeq0TPkT548gUajwcmTJ5Gf/3/v/Hv//ffrLDAiIqKq1Kh4HT16FEePHq3rWIiIiGqkRsWrrJ8NEckvOTkZubm5KCkpQXFxcaUvQt26dSvGjRuHgoICzJw5E2q1WoZIiepOjYrXrVu3Kv27Licnp1oP6GUmT56M0NBQdO7cGdevXwdQ+gr+jRs3wt7eHrm5ubh37x5WrlyJuLg4rF69GnPmzMGDBw+kYwwbNgw5OTk6j52otgwfPrzK93OW7/7br18/7Ny5E/3799dxhER1q0bFq0+fPtLXZmZmeOutt9C8efM6C6o6Xl5eiIyMhKenJ9auXYuWLVviwIED8Pb2xoULpV1mBw4cCCcnJ8TFlbaP2Lx5Mz777LMan4OdlJVL17kt7TZAZ+eqKXb/pYagRn/nlZWVJY20tDRs3boVI0aMqOvYKmjcuDEGDhyI2bNnw9PTEwDg6+uLwMBAqXABwH//+18cPnxY5/ER6YIQAuHh4fjll18wZ86cCtvZ/Zcaghpdebm6ukpfq1Qq9OnTR2ruqEuTJ0/G8ePHkZiYiKysLLi6uqJr164IDAysdr8PPvgAb7/9NgAgOzu70sJbvpOyoYEK3k5VN6tUutdMG+ltfrrObUiU7pqWOjs7IyoqCo8fP8bz589hZGSELVu2YMmSJVKnX6C0+6+fn59W99+goKBX7v6ra2X56SPmVvtqVLzK33IrLi5GcnIypk2bVmdBVcXLywtbtmwBAISEhMDLy6vCnIsXL8LCwgLh4eHSW0Bqcttwz5492LNnD4DSTsr63LFWnzvy6jq3pW/o7rZhZV1qV69ejby8PK1/35V1/x05cmS9v23YULoN65sXOynrSo2K1+zZs5GcnKy1ztHRsS7iqVLz5s0xYsQIuLi4QAgBQ0NDCCEQGBiIXr16ISwsDADQv39/TJkyBRMmTPjd53pW+KRefpZRW4ZERen0h64u6XNuAGBubg6VSoW8vDyYm5tjzJgx+OSTT7TmhIWFwdfXFyEhIejXrx9ycnLqfeEielU1+szr4MGDNVpXl6ZOnYqgoCA4Ojqibdu2aNOmDZKTkxEeHo6ZM2diwID/+4Flbm6u09iIdKVVq1Y4f/48YmJicPnyZRw9ehQnTpzAvHnzpA7Ax44dw61bt5CUlIQ9e/Zg/vz5MkdNVPuqvfLq1KkTunbtCktLS/z5z3+W1ltYWMDMzKzOgyvPy8sL69ev11p36NAheHt7Y/r06diwYQPs7e1x//59ZGZmav02Wv4zL6D0s7PffvtNZ7ET1Zbk5GT07Nmzwvrdu3drLfv6+uooIiJ5vLR4TZgwAVZWVpg4caK0Pjc3t9KnnOrS8OHDK6zbvn279PWwYcMq3W/t2rVYu3ZtXYVFREQyqLZ4hYWFISwsDP3798fFixd1FRMREVG1avTAhlqtxvz589G1a1et24WzZ8+us8CIiIiqUqMHNvbv3w8bGxuMHTsWZ8+eRevWrZGbm1vXsREREVWqRsWrffv2+Pjjj5Gfn4+goCCMHz8e3bp1q+vYiIiIKlWj4lVUVAQAePTokfT0oa7/zouIiKhMjT7z+vLLL2FlZYV//OMfCAsLQ5MmTfDxxx/XdWxERESVqlHx8vf3BwCcO3dOljYoRERE5dXotmHLli3h5+eHY8eOASh9EeOsWbPqNDAiIqKq1Kh47du3DydOnICdnR0A4MaNG9JLb4lIt5KTk/Hrr79CrVZX+SLUrVu3IjExEbGxsVpdIYj0RY2Kl7W1Nb799ls8f/4cAFBSUoKSkpI6DexFQghs2rRJWl66dClWr14tLc+ZMwcJCQlISEjApUuXMHDgQAClr4by8/OT5nl7e+OHH37QXeBEdWD48OFwdXWt9E3l5Tspz507Fzt37pQhQqK6VaPPvPLz89G8eXMIIQBAelO1Lj158gRvvvkm1q1bV6H9+fjx4zFv3jwMGjQIDx8+hKurK77//nv07dsX27Ztwy+//II//elPuHr1Kv71r39h5MiR1Z6LnZSVi52U2UmZGoYaXXktWbIEYWFhcHJywvnz5xEUFISFCxfWdWxaiouL8eWXX+KDDz6osG3FihVYvny5VNTUajUCAwOxYMEClJSUYP78+dixYwc2btyIvXv3VmjvQqQk7KRMBBgAEFVtfP3116X/CQwNDdGpUycYGBjg+vXrKC4u1lWMAEpfBmxnZ4dff/0VPXr0wJw5c9CkSROsXbsWDx8+RNu2bfH48WNp/qRJk+Dj44MpU6YAAIKDg9GvXz84Ozvj2bNnFY5fvpNyr969cf9Jvm4Sk8Frpo3w8Gmh3GHUCV3nlnr1ms7O5ezsjISEBBgbG6OoqAhGRkbo2LEj7ty5U6GTcnp6ulYn5dTUVEV0Uk5ISJA7jDrRkHLTVdPNam8bfv/99+jduzcA4JtvvsHUqVN1ElRVcnNzERQUhEWLFqGwsPofUAYGBtJtzsaNG6NPnz4wNjZGixYtcPfu3Qrz2UlZP7CTMjsp10cNJbd600nZwMBA+rpdu3Z1HkxNbNmyBVeuXEFAQIC0Lj4+Hr1790ZERIS0rlevXoiPjwdQ2hblq6++QkZGBjZv3oxp06ZVew52UlYufc4NYCdlojLVFq+yK5cXv5ZTdnY2Dhw4gNmzZ2Pv3r0AgI0bN2LDhg1wc3NDVlYWevTogZkzZ6Jfv35wcXHB+PHj0bNnTzx79gyzZs3CqFGjcOrUKZkzIXp1rVq1QmhoKADAyMgIwcHBUidloLQp5bFjxzBu3DgkJSWhoKAA77zzjpwhE9UZUdUoLi4WOTk54vHjx6KoqEjk5ORIyzk5OVXuVxcjNzdX+rply5YiPz9frF69Wlr33nvviWvXromEhARx+fJlMXjwYAFAREZGCjc3N2le7969xdWrV4WxsXGV58rLy9NpbroeUVFRssfA3JhbQ8qvoeSmyzyrvfIyMqrRk/Q60bRpU+nr+/fvo3Hjxlrbd+3ahV27dlXYb/DgwVrL0dHR6Nq1a90ESUREOlGjR+WJiIjqExYvIiJSHBYvIiJSHBYvIiJSHBYvIiJSHBYvIiJSHBYvIiJSHBYvIiJSHBYvIoVhJ2Wiel68WrVqhf/93/9FUlISrl69iqNHj6JDhw4oKCiAWq3G1atXERgYKL0JZOjQoThy5AgAwMfHB0IIjBgxQjre5MmTIYSQ2qQQKRU7KVNDV6+LV2hoKM6cOYP27duja9euWLVqFVq1aoWbN2/C1dUV3bp1Q+vWrat8S/yvv/4KLy8vadnT0xMxMTE6ip5IHlV1UibSJ/Xn5YUvGD58OIqKirB7925pXWxsLBwcHKTl58+f4/Lly1V2iY2MjMTgwYNhZGQEU1NTtG/fvkbFy6SRmU5byetaa6fOepufrnOTo3VOWSdlIQR2794t9aErU1UnZbZFIX1Sb4uXi4sLoqOjq51jamqKfv364f333690uxACp06dwtixY2FpaYmwsDC0bdu20rnlOykbGqjg7eTyxxKox14zbaS3+ek6tyE6bL7n7OyMqKgoPH78GM+fP4eRkRG2bNmCJUuWVOik7Ofnp9VJOSgoSBGdlHXZzFCXmFvtq7fFqzpOTk5Qq9Xo0KEDDh48CI1GU+XckJAQLFq0CJaWlli6dClWrVpV6Tx2UtYP7KTMTsr1UUPJrd50UpbT1atXMXXq1Eq3lX3mZWNjgzNnzmDixInSgxovioqKgouLCwoLC5GYmFijc7OTsnLpc24AOykTlam3D2z89NNPMDU1xbvvviut69Onj9ZnXunp6Vi5ciU+/PDDao/14YcfVnnFRaQkrVq1wvnz5xETE4PLly/j6NGjUiflsm7Kx44dw61bt5CUlIQ9e/Zg/vz5MkdNVPvq7ZUXAPz5z3/Gli1bsHLlSjx58gS3b9/G4sWLteZ8//33WLNmDQYNGlTlcY4fP17HkRLpRnJyMnr27FlhffkHmwDA19dXRxERyUf2NtL1beTl5ckeQ12OhtKSXN+GPuem7/k1lNx0mWe9vW1IRERUFRYvIiJSHBYvIiJSHBYvIiJSHBYvIiJSHBYvIiJSHBYvIiJSHBYvIiJSHBYv0jumpqa4dOkSYmJiEBcXhzVr1lQ6j92GiZSrzopXcXEx1Go1NBoNDhw4ADs7O6jVaqjVaty7dw+pqanSsrGxsdb8sLAwWFpaah0vJiYGwcHBAICZM2dK+z59+lRqib5u3Tr4+Phg+/bt0n5z5sxBQkICEhIScOnSJQwcOLCuUqZ64unTpxgxYgR69uyJnj17ws3NDf369dOaw27DRMpWZ8WrsLBQ6nb87NkzTJ8+Ha6urnB1dcWuXbuwefNmabmoqEhrflZWFhYsWCAdq3PnzlCpVBgyZAjMzc2xb98+ad+0tDSpJfqLL+gdP3485s2bh0GDBsHZ2RnvvfcegoOD0apVq7pKm+qJ/Px8AICxsTGMjY0hhNDazm7DRMqmkxfzRkZGonv37jWef+HCBa353t7e2L9/P5ydnTFp0iSpT9HLrFixAsuXL8fDhw8BAGq1GoGBgViwYAE+/vjjKvdjJ+XaI1drGZVKhejoaLRv3x47duzA5cuXtbaz2zCRstV58TI0NIS7u3uN3+yuUqkwcuRI+Pv7S+umT5+O0aNHo1OnTlKfopro2rVrhW7Mv/zyC3x8fCrMZSfluqHLTsOAdlfX4uJiJCYm4m9/+xvGjx+PJ0+eSPOU2G1Yn7vxAvqdH3OrfXVWvBo1agS1Wg2g9MqrfDGqbr6joyOio6Nx8uRJAKU9vB48eIA7d+4gNTUVe/fuhZWVFR49evS74jIwMKhwCwlgJ+W6ouvGkJV1rP3444+Rn5+v+G7D+tyNF9Dv/BpKbnrRSbnsM6xXnW9hYYEffvgBCxYswPbt2+Hl5YXOnTsjOTkZAGBhYYEpU6a8tBgCQHx8PHr37o2IiAhpXa9evRAfH1/tfuykrGzW1tYoKipCTk4OzMzMMGrUKGzYsEFrDrsNEylbvXtU/vHjx1i0aBGWLVsGExMTvPXWW+jevTvatm2Ltm3bwsPDA15eXjU61saNG7FhwwY0b94cANCjRw/MnDkT//M//1OXKZDMbG1tERERgdjYWERFReHkyZM4evQouw0T6ZF62Uk5JiYGsbGxmDZtGu7evYu0tDRp27lz59ClSxfY2Ni89DflI0eOwN7eHj///DOEEMjNzcXbb7/N37D1nEajQa9evSqsZ7dhIv0ieyfO+jbYSVm5g7kpd+hzfg0lN3ZSJiIiqgaLFxERKQ6LFxERKQ6LFxERKQ6LFxERKQ6LFxERKQ6LFxERKQ6LFxERKQ6LF+kddlIm0n+KKl7Nmzevshtzy5Yt8ezZM6mtCQA0adIESUlJaN++PQDAyMgIv/76K/r27StXCqQD7KRMpP8UVbyysrKq7MY8ZcoUXLx4UeulvXl5efjwww+xY8cOAMCyZcvw888/V2hMSPqHnZSJ9Fu9fDHv7+Hl5YWlS5ciODgYdnZ20st8v/32W8yaNQvLly/He++9V6PbQ+ykXHvYSZmI6oKirryq0rp1a9jY2CAqKgoHDhzA9OnTtbYvXrwYGzduxL/+9S9kZ2fLFCXp0vPnz+Hq6orWrVujb9++6Nq1q9Z2AwODCvtU1qSUiOonvbjy8vT0xIEDBwAAISEh8Pf3x+bNm6Xtbm5uSEtLg4uLS5XHmDNnjvR5maGBCt5OVc9VutdMG+ksvyE6bg9eWUtyW1tb/Pjjj8jIyJDWOTg4ICgoCFlZWQAAFxcX7N27F0VFRTqN91Xocyt5QL/zY251Q/ZX6v+esXr1arF06VIBQERHR4vU1FSRnJwskpOTxdOnT0X79u0FAGFraytu3rwp7O3txY0bN0S3bt1eemy2RFHuiIqKEtbW1sLS0lIAEGZmZuLcuXNi/PjxWvPGjRsnjh07JgCIfv36iUuXLskee0P+76bv+TWU3NgS5RV07NgRjRs3RuvWraVuy+vWrYOnpycAYPPmzfj0009x9+5dLFmyRHp4g/QXOykT6T/F3zb08vJCaGio1rpDhw4hJCQEFy9eRJs2beDv7w8A+OGHHzBnzhzMmDFDetKM9A87KRPpP8UWr7Vr11a5TaPRSB/Qnzp1Smubh4dHncZFRER1T/G3DYmIqOFh8SIiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8SIiIsVh8Wqg/P39kZGRAY1GU+WcrVu3IjExEbGxsTXqg0ZEpCuKKV7FxcVQq9XQaDQICwuDpaWl1vaYmBgEBwdrrQsICMCtW7cQExOD69evIzAwEHZ2droMu97at28f3Nzcqtzu7u6ODh06oEOHDpg7dy527typw+iIiKqnmHcbFhYWSr/979u3DwsWLMCnn34KAOjcuTNUKhWGDBkCc3NzFBQUSPstX74chw4dAlDalDIiIgIuLi7V9m3SdSdlOboNR0ZGwsHBocrtHh4e0suLL126BCsrK9jY2LDTMBHVC4q58irvwoULsLe3l5a9vb2xf/9+hIeHY9KkSVXut2XLFqSnp8Pd3V0XYSqavb09UlJSpOXU1FSt7zkRkZwUc+VVRqVSYeTIkVKbEwCYPn06Ro8ejU6dOsHX1xchISFV7n/lyhV07twZYWFhWuvl7KQsV7dhExMTODk5VdoFtX379vDz80NeXh6A0r5pQUFBWle19RE71iqXPufH3OqG7J04azKKi4uFWq0W2dnZ4tSpU0KlUgkAok+fPuL8+fOlnTVVKpGSkiKsrKwEABEQECCmTJmidZwtW7aIv//979Weq6F0UnZwcBAajabSObt27RKenp7S8rVr14SNjY3ssdc0N30c+pybvufXUHJjJ+VKlH3m5eDgABMTEyxYsABAaTPKzp07Izk5GTdv3oSFhQWmTJlS5XFcXV2RkJCgq7AVKywsDDNmzAAA9OvXDzk5Ofy8i4jqDcXdNnz8+DEWLVqEw4cPY/fu3XjrrbfQvXt3pKWlAQCGDRuGjz76SOu2YpmFCxfC1tYWx48f13XY9U5wcDCGDRsGa2trpKSkYPXq1TA2NgZQ2nH42LFjGDduHJKSklBQUIB33nlH5oiJiP6P4ooXUPpYfGxsLKZNm4a7d+9KhQsAzp07hy5dusDGxgYA8J///Af/+Mc/YG5ujosXL2L48OHVPmnYUHh7e790jq+vrw4iISJ6dYopXk2bNtVaLnuq8KuvvtJa//z5c+lvuXi1QESknxTzmRcREVEZFi8iIlIcFi8iIlIcFi8iIlIcFi8iIlIcFi8iIlIcFi8iIlIcFi8iIlIcFi8iIlIcFi8iIlIcFi8iIlIcFi8iIlIcA5Q29qJyHj9+jOvXr8sdRp2xtrZGZmam3GHUCeamXPqcX0PJzcHBAS1bttTZuWXvxFnfhj53PdX3/Jibcoc+58fcan/wtiERESkOixcRESkOi1clvvzyS7lDqFP6nB9zUy59zo+51T4+sEFERIrDKy8iIlIcFi8iIlIcFq8XjB07FteuXUNiYiJWrFghdzi1pnXr1vjpp58QHx+PuLg4LFq0SO6Qap1KpcKVK1dw5MgRuUOpdZaWlvj222+RkJCA+Ph49O/fX+6Qas3ixYsRFxcHjUaD4OBgmJqayh3SH+Lv74+MjAxoNBppXbNmzRAeHo4bN24gPDwcVlZW8gX4B1SW28aNG5GQkIDY2Fh89913sLS01Fk8sv+dQH0ZKpVKJCUlibZt2wpjY2MRExMjnJ2dZY+rNoaNjY1wdXUVAESTJk3E9evX9Sa3svHBBx+Ir7/+Whw5ckT2WGp77Nu3T8yePVsAEMbGxsLS0lL2mGpj2NnZiVu3bgkzMzMBQHzzzTfCx8dH9rj+yBg8eLBwdXUVGo1GWrdhwwaxYsUKAUCsWLFCrF+/XvY4ayu30aNHC0NDQwFArF+/Xme58cqrnL59+yIpKQnJyckoKipCSEgIPDw85A6rVqSnp0OtVgMA8vLykJCQAHt7e5mjqj329vYYP348/Pz85A6l1jVt2hRDhgyBv78/AKCoqAg5OTkyR1V7jIyM0KhRIxgaGsLc3BxpaWlyh/SHREZGIisrS2udh4cHAgMDAQCBgYGYPHmyDJH9cZXldvLkSZSUlAAALl68iNatW+skFhavcuzt7ZGSkiItp6am6tUP+DIODg5wdXXFpUuX5A6l1mzZsgV///vf8fz5c7lDqXXt2rXDgwcPEBAQgCtXrmDPnj0wNzeXO6xakZaWhk2bNuHOnTu4d+8ecnJycPLkSbnDqnWtWrVCeno6gNJfJHX5CiVdmjVrFn788UednIvFqxwDA4MK64QQMkRSdxo3boxDhw5h8eLFyM3NlTucWjF+/Hjcv38fV65ckTuUOmFkZIRevXph586d6NWrF/Lz87Fy5Uq5w6oVVlZW8PDwQNu2bWFnZ4fGjRvjL3/5i9xh0e+watUqFBcX4+uvv9bJ+Vi8yklNTcXrr78uLbdu3VrxtzDKMzIywqFDh/D1118jNDRU7nBqzcCBAzFp0iQkJycjJCQEI0aMwP79++UOq9akpqYiNTUVly9fBgAcPHgQvXr1kjmq2jFq1CgkJycjMzMTxcXF+O677/CnP/1J7rBqXUZGBmxsbAAANjY2uH//vswR1a4ZM2ZgwoQJOv3Fg8WrnKioKHTo0AGOjo4wNjaGp6cnwsLC5A6r1vj7+yMhIQGbN2+WO5RatWrVKrz++uto27YtPD098dNPP+Gvf/2r3GHVmoyMDKSkpKBjx44AgJEjRyI+Pl7mqGrHnTt30L9/fzRq1AhAaW4JCQkyR1X7wsLC4OPjAwDw8fHB4cOHZY6o9owdOxYrVqzApEmTUFhYqNNzy/4ES30a7u7u4vr16yIpKUmsWrVK9nhqawwcOFAIIURsbKxQq9VCrVYLd3d32eOq7TF06FC9fNqwR48eIioqSsTGxorQ0FBhZWUle0y1NdasWSMSEhKERqMRQUFBwsTERPaY/sgIDg4WaWlp4tmzZyIlJUXMmjVLNG/eXJw6dUrcuHFDnDp1SjRr1kz2OGsrt8TERHHnzh3p58rOnTt1EgtfD0VERIrD24ZERKQ4LF5ERKQ4LF5ERKQ4LF5ERKQ4LF5ERKQ4RnIHQNSQFBcXa72Re/Lkyfjtt99kjIhImfioPJEO5ebmomnTpjo7n6GhofTSVCJ9wtuGRPWIjY0Nzp49C7VaDY1Gg0GDBgEofYtBdHQ0YmJicOrUKQClPaJCQ0MRGxuLCxcuoFu3bgCA1atXY/fu3Thx4gSCgoJgbW2NgwcP4vLly7h8+bJevn6JGibZ/2qbg6OhjOLiYulNBN99912F7UuWLJHe7KJSqUSTJk2EtbW1uHPnjnB0dBQApLczbNu2TXz88ccCgBg+fLhQq9UCgFi9erX45ZdfpB5ZX3/9tRg4cKAAIF5//XURHx8v+/eBg+OPDn7mRaRDhYWFcHV1rXJ7VFQU9u7dC2NjY3z//feIjY3FsGHDcO7cOdy+fRsAkJ2dDQAYNGgQpkyZAgCIiIjAa6+9BgsLCwCl79J78uQJgNKX33bp0kU6h4WFBZo0aYK8vLy6SJFIJ1i8iOqRyMhIDBkyBOPHj8f+/fvxn//8B48ePaq0NU91LXzy8/OldSqVCgMGDJCKGZE+4GdeRPVImzZtcP/+ffj5+cHf3x+9evXChQsXMHToUDg6OgIo/awLAM6dOye1oBg6dCgyMzMr7dEWHh4OX19fablHjx51nwhRHeOVF1E9MmzYMCxfvhxFRUXIy8vDjBkzkJmZiblz5+K7776DSqXC/fv3MWbMGKxZswYBAQGIjY1FQUGB1HLjRYsWLcKOHTsQGxsLIyMjnDt3Dn/72990nBlR7eKj8kREpDi8bUhERIrD4kVERIrD4kVERIrD4kVERIrD4kVERIrD4kVERIrD4kVERIrz/wDKdLMAMn4G/gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(xg_reg)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6bdb6bebcaa6c165db367a86e382ae8df75f09257c40532b854029e0e3d706f"
  },
  "kernelspec": {
   "display_name": "lighthouse",
   "language": "python",
   "name": "lighthouse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
