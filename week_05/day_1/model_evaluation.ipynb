{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Models Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate evaluation, we won't be using any regression model but will generate original values and predictions from the model by `Numpy` instead. Let's begin by importing `Numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 'ground truth'\n",
    "y_true = np.random.normal(0, 1, 10)\n",
    "\n",
    "# generate random errors\n",
    "errors = np.random.normal(0, 0.02, 10)\n",
    "\n",
    "# simulate predictions\n",
    "y_pred = y_true + errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Squared Error (MSE) / Root Means Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007924480375039288\n"
     ]
    }
   ],
   "source": [
    "# import MSE from sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# compute MSE\n",
    "MSE = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "# print MSE\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All regression evaluation functions from `sklearn.metrics` take two mandatory arrays as parameters. The first is an array with ground truth values (in our case `y_true` variable) and the second is our prediction (in outcase `y_pred` variable).\n",
    "\n",
    "To get RMSE from MSE, we have two options:\n",
    "1. Compute the square root from MSE using `Numpy`.\n",
    "2. Use the `squared=False` option in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028150453593218154\n",
      "0.028150453593218154\n"
     ]
    }
   ],
   "source": [
    "# RMSE by Numpy\n",
    "RMSE = np.sqrt(MSE)\n",
    "print(RMSE)\n",
    "\n",
    "# RMSE by sklearn\n",
    "RMSE = mean_squared_error(y_true, y_pred, squared=False)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the regression model evaluation, we will use synthetic data. The only difference being that we will need predicted probabilities instead of predicted labels (predicted values in regression). The important thing to mention is that we are simulating the behaviour of a binary classifier, meaning that the predicted class is only positive (returns 1) or negative (returns 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "y_true = [1, 1, 0, 1, 0, 0, 1, 0, 0, 1]\n",
    "\n",
    "# simulate probabilities of positive class\n",
    "y_proba = [0.9, 0.7, 0.2, 0.99, 0.7, 0.1, 0.5, 0.2, 0.4, 0.6]\n",
    "\n",
    "# set the threshold to predict positive class\n",
    "thres = 0.5\n",
    "\n",
    "# class predictions \n",
    "y_pred = [int(value > thres) for value in y_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 1, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `threshold` value is set to 0.5. All observations with probabilities above this threshold are assigned to the positive class and stored in the `y_pred` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# import accuracy_score from sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# compute accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# print accuracy\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8000000000000002\n"
     ]
    }
   ],
   "source": [
    "# import f1_score from sklearn\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# compute F1-score\n",
    "f1= f1_score(y_true, y_pred)\n",
    "\n",
    "# print F1-score\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AUC-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# import roc_auc_score from sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# compute AUC-score\n",
    "auc = roc_auc_score(y_true, y_proba)\n",
    "\n",
    "# print AUC-score\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In `row_auc_score`, we use probabilities `y_proba` instead of class labels. If we passed class labels, no errors would be shown but the score would be inaccurate. Be careful and *read the documentation* before using `Sklearn` functions."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6bdb6bebcaa6c165db367a86e382ae8df75f09257c40532b854029e0e3d706f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('lighthouse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
